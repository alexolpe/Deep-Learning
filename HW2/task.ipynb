{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_limited = torch.randint(0, 33, (4, 3, 5, 9)).type(torch.uint8)\n",
    "\n",
    "images_limited_scaled_manual = images_limited / images_limited.max().float()\n",
    "\n",
    "images_limited_scaled_automated = torch.zeros_like(images_limited).float()\n",
    "for i in range(images_limited.shape[0]):\n",
    "    images_limited_scaled_automated[i] = tvt.ToTensor()(numpy.transpose(images_limited[i].numpy(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_spanded = torch.randint(0, 256, (4, 3, 5, 9)).type(torch.uint8)\n",
    "\n",
    "images_spanded_scaled_manual = images_spanded / images_spanded.max().float()\n",
    "\n",
    "images_spanded_scaled_automated = torch.zeros_like(images_spanded).float()\n",
    "for i in range(images_spanded.shape[0]):\n",
    "    images_spanded_scaled_automated[i] = tvt.ToTensor()(numpy.transpose(images_spanded[i].numpy(), (1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = numpy.load('filename.npy')\n",
    "max_value = numpy.max(img_array)\n",
    "min_value = numpy.min(img_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece60146",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
